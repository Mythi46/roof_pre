#!/usr/bin/env python3
"""
æœ¬åœ°æ•°æ®é›†ä¸‹è½½è„šæœ¬
Local dataset download script

ä¸‹è½½å«æ˜Ÿå›¾åƒåˆ†å‰²æ•°æ®é›†åˆ°æœ¬åœ°
"""

import os
import sys
import yaml
import shutil
from pathlib import Path

print("ğŸ“¥ æœ¬åœ°æ•°æ®é›†ä¸‹è½½å™¨")
print("=" * 40)

# æ£€æŸ¥ä¾èµ–
try:
    from roboflow import Roboflow
    print("âœ… Roboflowåº“å·²å®‰è£…")
except ImportError:
    print("âŒ Roboflowåº“æœªå®‰è£…")
    print("æ­£åœ¨å®‰è£…...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "roboflow"])
    from roboflow import Roboflow
    print("âœ… Roboflowåº“å®‰è£…å®Œæˆ")

# æ•°æ®é›†é…ç½®
DATASET_CONFIG = {
    "workspace": "a-imc4u",
    "project": "new-2-6zp4h", 
    "version": 1,
    "format": "yolov8"
}

# å°è¯•å¤šä¸ªAPIå¯†é’¥
API_KEYS = [
    "EKxSlogyvSMHiOP3MK94",  # åŸå§‹å¯†é’¥
    # å¦‚æœæ‚¨æœ‰å…¶ä»–å¯†é’¥ï¼Œå¯ä»¥æ·»åŠ åœ¨è¿™é‡Œ
]

def download_with_api_key(api_key):
    """ä½¿ç”¨æŒ‡å®šAPIå¯†é’¥ä¸‹è½½æ•°æ®é›†"""
    try:
        print(f"ğŸ”‘ å°è¯•APIå¯†é’¥: {api_key[:10]}...")
        
        rf = Roboflow(api_key=api_key)
        project = rf.workspace(DATASET_CONFIG["workspace"]).project(DATASET_CONFIG["project"])
        
        # è®¾ç½®ä¸‹è½½è·¯å¾„
        download_path = os.path.join(os.getcwd(), "data", "raw")
        os.makedirs(download_path, exist_ok=True)
        
        print(f"ğŸ“‚ ä¸‹è½½åˆ°: {download_path}")
        
        # ä¸‹è½½æ•°æ®é›†
        dataset = project.version(DATASET_CONFIG["version"]).download(
            model_format=DATASET_CONFIG["format"],
            location=download_path
        )
        
        return dataset
        
    except Exception as e:
        print(f"âŒ APIå¯†é’¥å¤±è´¥: {str(e)}")
        return None

def setup_data_yaml(dataset_location):
    """è®¾ç½®æ•°æ®é…ç½®æ–‡ä»¶"""
    try:
        # åŸå§‹data.yamlè·¯å¾„
        original_yaml = os.path.join(dataset_location, "data.yaml")
        
        if not os.path.exists(original_yaml):
            print(f"âŒ æœªæ‰¾åˆ°data.yaml: {original_yaml}")
            return False
        
        # è¯»å–åŸå§‹é…ç½®
        with open(original_yaml, 'r') as f:
            data_config = yaml.safe_load(f)
        
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   ç±»åˆ«æ•°é‡: {data_config.get('nc', 'N/A')}")
        print(f"   ç±»åˆ«åç§°: {data_config.get('names', 'N/A')}")
        
        # æ›´æ–°è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
        base_path = os.path.abspath(dataset_location)
        data_config['path'] = base_path
        data_config['train'] = os.path.join(base_path, 'train', 'images')
        data_config['val'] = os.path.join(base_path, 'valid', 'images')
        data_config['test'] = os.path.join(base_path, 'test', 'images') if os.path.exists(os.path.join(base_path, 'test')) else data_config['val']
        
        # ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•
        project_yaml = os.path.join(os.getcwd(), "config", "data.yaml")
        os.makedirs(os.path.dirname(project_yaml), exist_ok=True)
        
        with open(project_yaml, 'w') as f:
            yaml.dump(data_config, f, default_flow_style=False)
        
        print(f"âœ… æ•°æ®é…ç½®å·²ä¿å­˜: {project_yaml}")
        
        # éªŒè¯æ•°æ®é›†
        train_images = os.path.join(base_path, 'train', 'images')
        val_images = os.path.join(base_path, 'valid', 'images')
        
        if os.path.exists(train_images):
            train_count = len([f for f in os.listdir(train_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            print(f"ğŸ“Š è®­ç»ƒå›¾åƒ: {train_count} å¼ ")
        
        if os.path.exists(val_images):
            val_count = len([f for f in os.listdir(val_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            print(f"ğŸ“Š éªŒè¯å›¾åƒ: {val_count} å¼ ")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®¾ç½®æ•°æ®é…ç½®å¤±è´¥: {e}")
        return False

def download_alternative_dataset():
    """ä¸‹è½½æ›¿ä»£æ•°æ®é›†ï¼ˆå¦‚æœä¸»æ•°æ®é›†ä¸å¯ç”¨ï¼‰"""
    print("\nğŸ”„ å°è¯•ä¸‹è½½æ›¿ä»£æ•°æ®é›†...")
    
    try:
        # ä½¿ç”¨å…¬å¼€çš„ç¤ºä¾‹æ•°æ®é›†
        from ultralytics import YOLO
        
        # è¿™ä¼šè‡ªåŠ¨ä¸‹è½½COCO8åˆ†å‰²æ•°æ®é›†
        model = YOLO('yolov8n-seg.pt')
        
        # åˆ›å»ºç¤ºä¾‹é…ç½®
        demo_config = {
            'path': os.path.abspath('data/demo'),
            'train': 'images/train',
            'val': 'images/val',
            'nc': 4,
            'names': ['Baren-Land', 'farm', 'rice-fields', 'roof']
        }
        
        # ä¿å­˜æ¼”ç¤ºé…ç½®
        os.makedirs('config', exist_ok=True)
        with open('config/data.yaml', 'w') as f:
            yaml.dump(demo_config, f, default_flow_style=False)
        
        print("âœ… æ¼”ç¤ºæ•°æ®é›†é…ç½®å·²åˆ›å»º")
        print("ğŸ’¡ æ‚¨å¯ä»¥ç¨åæ›¿æ¢ä¸ºçœŸå®çš„å«æ˜Ÿå›¾åƒæ•°æ®")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½æ›¿ä»£æ•°æ®é›†å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¸‹è½½å«æ˜Ÿå›¾åƒåˆ†å‰²æ•°æ®é›†...")
    
    dataset = None
    
    # å°è¯•ä½¿ç”¨APIå¯†é’¥ä¸‹è½½
    for api_key in API_KEYS:
        dataset = download_with_api_key(api_key)
        if dataset:
            break
    
    if dataset:
        print(f"âœ… æ•°æ®é›†ä¸‹è½½æˆåŠŸ!")
        print(f"ğŸ“ ä½ç½®: {dataset.location}")
        
        # è®¾ç½®æ•°æ®é…ç½®
        if setup_data_yaml(dataset.location):
            print("âœ… æ•°æ®é›†é…ç½®å®Œæˆ")
        else:
            print("âš ï¸ æ•°æ®é›†é…ç½®å¯èƒ½æœ‰é—®é¢˜")
        
        # æ˜¾ç¤ºä¸‹è½½ç»“æœ
        print(f"\nğŸ“Š ä¸‹è½½å®Œæˆ:")
        print(f"   æ•°æ®é›†è·¯å¾„: {dataset.location}")
        print(f"   é…ç½®æ–‡ä»¶: config/data.yaml")
        print(f"   å¯ä»¥å¼€å§‹è®­ç»ƒ: python train_expert_simple.py")
        
    else:
        print("âŒ æ‰€æœ‰APIå¯†é’¥éƒ½å¤±è´¥äº†")
        print("ğŸ”„ å°è¯•ä¸‹è½½æ›¿ä»£æ•°æ®é›†...")
        
        if download_alternative_dataset():
            print("âœ… æ›¿ä»£æ•°æ®é›†å‡†å¤‡å®Œæˆ")
            print("ğŸ’¡ å»ºè®®:")
            print("   1. è·å–æœ‰æ•ˆçš„Roboflow APIå¯†é’¥")
            print("   2. æˆ–è€…æ‰‹åŠ¨ä¸‹è½½å«æ˜Ÿå›¾åƒæ•°æ®é›†")
            print("   3. å°†æ•°æ®æ”¾åœ¨ data/raw/ ç›®å½•ä¸‹")
        else:
            print("âŒ æ— æ³•å‡†å¤‡ä»»ä½•æ•°æ®é›†")
            return False
    
    # åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
    directories = [
        "data/raw",
        "data/processed", 
        "models/pretrained",
        "models/trained",
        "results/training",
        "results/evaluation",
        "logs"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        # åˆ›å»º.gitkeepæ–‡ä»¶
        gitkeep_path = os.path.join(directory, ".gitkeep")
        if not os.path.exists(gitkeep_path):
            with open(gitkeep_path, "w") as f:
                f.write("")
    
    print(f"\nğŸ“ é¡¹ç›®ç›®å½•ç»“æ„å·²åˆ›å»º")
    
    # æ˜¾ç¤ºä¸‹ä¸€æ­¥
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"   1. æ£€æŸ¥æ•°æ®: ls data/raw/")
    print(f"   2. å¼€å§‹è®­ç»ƒ: python train_expert_simple.py")
    print(f"   3. æˆ–ä½¿ç”¨GPUç‰ˆæœ¬: python test_gpu_training.py")
    
    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ æ•°æ®é›†ä¸‹è½½å®Œæˆ!")
    else:
        print("\nâŒ æ•°æ®é›†ä¸‹è½½å¤±è´¥")
        sys.exit(1)
