#!/usr/bin/env python3
"""
Generate 50 images visualization results
ç”Ÿæˆ50ç»„å›¾åƒå¯è§†åŒ–ç»“æœ
"""

import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pathlib import Path
import random
from ultralytics import YOLO
import yaml
from PIL import Image
import json
from datetime import datetime

# è®¾ç½®matplotlibä½¿ç”¨è‹±æ–‡æ˜¾ç¤ºï¼Œé¿å…ä¹±ç é—®é¢˜
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
print("âœ… Set charts to use English display")

def find_test_images_extended(data_yaml_path, num_images=50):
    """ä»æ•°æ®é›†ä¸­é€‰å–50å¼ æµ‹è¯•å›¾ç‰‡"""
    print("ğŸ” Finding 50 test images...")
    
    try:
        with open(data_yaml_path, 'r') as f:
            data_config = yaml.safe_load(f)

        # è·å–æ•°æ®é›†æ ¹ç›®å½•
        dataset_root = Path(data_yaml_path).parent

        # å°è¯•å¤šä¸ªå¯èƒ½çš„å›¾ç‰‡ç›®å½•
        possible_dirs = []
        for key in ['test', 'val', 'train']:
            if key in data_config:
                rel_path = data_config[key]
                if rel_path.startswith('../'):
                    # å¤„ç†ç›¸å¯¹è·¯å¾„
                    abs_path = dataset_root / rel_path
                else:
                    abs_path = Path(rel_path)
                possible_dirs.append(abs_path)
        
        all_images = []

        for img_dir in possible_dirs:
            if img_dir and img_dir.exists():
                print(f"   ğŸ“ Checking directory: {img_dir}")
                image_files = [f for f in img_dir.iterdir()
                             if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]
                all_images.extend(image_files)
                print(f"   âœ… Found {len(image_files)} images in {img_dir}")
        
        # å¦‚æœå›¾ç‰‡ä¸å¤Ÿ50å¼ ï¼Œé‡å¤ä½¿ç”¨
        if len(all_images) < num_images:
            print(f"âš ï¸ Only found {len(all_images)} images, will repeat some images")
            # é‡å¤å›¾ç‰‡åˆ—è¡¨ç›´åˆ°è¾¾åˆ°50å¼ 
            multiplier = (num_images // len(all_images)) + 1
            all_images = (all_images * multiplier)[:num_images]
        else:
            # éšæœºé€‰æ‹©50å¼ 
            all_images = random.sample(all_images, num_images)
        
        print(f"âœ… Selected {len(all_images)} images for processing")
        return all_images
        
    except Exception as e:
        print(f"âŒ Error finding images: {e}")
        return []

def load_best_model():
    """åŠ è½½æœ€ä½³è®­ç»ƒæ¨¡å‹"""
    print("ğŸ”§ Loading best model...")
    
    # å¯èƒ½çš„æ¨¡å‹è·¯å¾„
    model_paths = [
        "runs/segment/improved_training_compatible/weights/best.pt",
        "runs/segment/continue_training_optimized/weights/best.pt",
        "results/roof_detection_training/weights/best.pt",
        "models/trained/best.pt",
        "best.pt",
        "yolov8l-seg.pt"  # é¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºåå¤‡
    ]
    
    for model_path in model_paths:
        if os.path.exists(model_path):
            print(f"âœ… Loading model: {model_path}")
            model = YOLO(model_path)
            return model, model_path
    
    print("âŒ No trained model found")
    return None, None

def predict_and_visualize_batch(model, image_paths, output_dir, batch_size=10):
    """æ‰¹é‡å¤„ç†å›¾ç‰‡ä»¥æé«˜æ•ˆç‡"""
    print(f"ğŸš€ Processing {len(image_paths)} images in batches of {batch_size}...")
    
    results_data = []
    
    for i in range(0, len(image_paths), batch_size):
        batch_paths = image_paths[i:i+batch_size]
        batch_end = min(i+batch_size, len(image_paths))
        
        print(f"ğŸ“¦ Processing batch {i//batch_size + 1}: images {i+1}-{batch_end}")
        
        for j, image_path in enumerate(batch_paths):
            global_index = i + j
            print(f"   ğŸ” Processing image {global_index+1}/50: {image_path.name}")
            
            try:
                # é¢„æµ‹
                results = model.predict(
                    source=str(image_path),
                    save=False,
                    conf=0.25,
                    iou=0.7,
                    verbose=False
                )
                
                # åŠ è½½åŸå›¾
                image = cv2.imread(str(image_path))
                if image is None:
                    print(f"   âŒ Failed to load image: {image_path}")
                    continue
                    
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # åˆ›å»ºå¯è§†åŒ–
                fig, axes = plt.subplots(1, 2, figsize=(16, 8))
                
                # åŸå›¾
                axes[0].imshow(image_rgb)
                axes[0].set_title(f'Original Image {global_index+1}: {image_path.name}', 
                                fontsize=14, fontweight='bold')
                axes[0].axis('off')
                
                # æ£€æµ‹ç»“æœ
                annotated_image = image_rgb.copy()
                
                # å¤„ç†æ£€æµ‹ç»“æœ
                detections = []
                if results and len(results) > 0:
                    result = results[0]
                    
                    if hasattr(result, 'boxes') and result.boxes is not None:
                        boxes = result.boxes.xyxy.cpu().numpy()
                        confidences = result.boxes.conf.cpu().numpy()
                        classes = result.boxes.cls.cpu().numpy()
                        
                        class_names = ['Baren-Land', 'farm', 'rice-fields', 'roof']
                        colors = [(139, 69, 19), (34, 139, 34), (65, 105, 225), (220, 20, 60)]
                        
                        for box, conf, cls in zip(boxes, confidences, classes):
                            x1, y1, x2, y2 = box.astype(int)
                            class_name = class_names[int(cls)] if int(cls) < len(class_names) else f"Class_{int(cls)}"
                            color = colors[int(cls)] if int(cls) < len(colors) else (255, 255, 255)
                            
                            # ç»˜åˆ¶è¾¹ç•Œæ¡†
                            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)
                            
                            # ç»˜åˆ¶æ ‡ç­¾
                            label = f'{class_name}: {conf:.2f}'
                            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                            cv2.rectangle(annotated_image, (x1, y1-label_size[1]-10), 
                                        (x1+label_size[0], y1), color, -1)
                            cv2.putText(annotated_image, label, (x1, y1-5), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                            
                            # è®°å½•æ£€æµ‹ç»“æœ
                            detections.append({
                                'class': class_name,
                                'confidence': float(conf),
                                'bbox': [int(x1), int(y1), int(x2), int(y2)]
                            })
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                axes[1].imshow(annotated_image)
                
                # ç”Ÿæˆæ ‡é¢˜
                num_detections = len(detections)
                if num_detections > 0:
                    class_counts = {}
                    for detection in detections:
                        class_name = detection['class']
                        if class_name not in class_counts:
                            class_counts[class_name] = 0
                        class_counts[class_name] += 1
                    
                    title_parts = [f'Detection Results ({num_detections} objects)']
                    for class_name, count in class_counts.items():
                        title_parts.append(f'{class_name}: {count}')
                    
                    title = '\n'.join(title_parts)
                else:
                    title = 'Detection Results (No objects detected)'
                
                axes[1].set_title(title, fontsize=14, fontweight='bold')
                axes[1].axis('off')
                
                # ä¿å­˜ç»“æœ
                result_filename = f"result_{global_index+1:02d}_{image_path.stem}.png"
                result_path = output_dir / result_filename
                plt.savefig(result_path, dpi=150, bbox_inches='tight')
                plt.close()
                
                # ä¿å­˜çº¯æ£€æµ‹ç»“æœå›¾
                detection_filename = f"detection_{global_index+1:02d}_{image_path.stem}.jpg"
                detection_path = output_dir / detection_filename
                cv2.imwrite(str(detection_path), cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))
                
                # è®°å½•ç»“æœæ•°æ®
                result_data = {
                    'image_index': global_index + 1,
                    'image_name': image_path.name,
                    'image_path': str(image_path),
                    'result_image': result_filename,
                    'detection_image': detection_filename,
                    'num_detections': num_detections,
                    'detections': detections
                }
                
                results_data.append(result_data)
                print(f"   âœ… Detected {num_detections} objects")
                
            except Exception as e:
                print(f"   âŒ Processing failed: {e}")
                continue
    
    return results_data

def create_extended_summary(results_data, output_dir):
    """åˆ›å»º50å¼ å›¾ç‰‡çš„æ€»è§ˆ"""
    print("ğŸ“Š Creating extended summary for 50 images...")
    
    # ç»Ÿè®¡æ•°æ®
    total_images = len(results_data)
    total_detections = sum(r['num_detections'] for r in results_data)
    
    # ç±»åˆ«ç»Ÿè®¡
    class_counts = {}
    confidence_scores = []
    
    for result in results_data:
        for detection in result['detections']:
            class_name = detection['class']
            if class_name not in class_counts:
                class_counts[class_name] = 0
            class_counts[class_name] += 1
            confidence_scores.append(detection['confidence'])
    
    # åˆ›å»ºæ€»è§ˆå›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
    if class_counts:
        colors = ['#DC143C', '#4169E1', '#8B4513', '#228B22']
        wedges, texts, autotexts = axes[0, 0].pie(
            class_counts.values(), 
            labels=class_counts.keys(), 
            colors=colors[:len(class_counts)],
            autopct='%1.1f%%', 
            startangle=90
        )
        axes[0, 0].set_title('Detection Distribution by Class', fontsize=14, fontweight='bold')
    
    # 2. ç±»åˆ«æ£€æµ‹æ•°é‡æŸ±çŠ¶å›¾
    if class_counts:
        bars = axes[0, 1].bar(class_counts.keys(), class_counts.values(), 
                            color=colors[:len(class_counts)], alpha=0.8)
        axes[0, 1].set_title('Detection Count by Class', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('Object Classes', fontsize=12)
        axes[0, 1].set_ylabel('Number of Detections', fontsize=12)
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 1,
                           f'{int(height)}', ha='center', va='bottom', fontweight='bold')
    
    # 3. æ¯å¼ å›¾ç‰‡æ£€æµ‹æ•°é‡åˆ†å¸ƒ
    detection_counts = [r['num_detections'] for r in results_data]
    axes[1, 0].hist(detection_counts, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
    axes[1, 0].set_title('Objects per Image Distribution', fontsize=14, fontweight='bold')
    axes[1, 0].set_xlabel('Number of Objects per Image', fontsize=12)
    axes[1, 0].set_ylabel('Frequency', fontsize=12)
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
    axes[1, 1].axis('off')
    
    stats_text = f"""Detection Results Summary (50 Images)

Total Images: {total_images}
Total Detections: {total_detections}
Average per Image: {total_detections/total_images:.1f} objects

Class Statistics:
"""
    
    for class_name, count in class_counts.items():
        percentage = (count / total_detections) * 100 if total_detections > 0 else 0
        stats_text += f"   {class_name}: {count} ({percentage:.1f}%)\n"
    
    if confidence_scores:
        stats_text += f"""
Confidence Statistics:
   Average: {np.mean(confidence_scores):.3f}
   Maximum: {np.max(confidence_scores):.3f}
   Minimum: {np.min(confidence_scores):.3f}
"""
    
    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes,
                    fontsize=12, verticalalignment='top',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.5))
    
    # è®¾ç½®æ€»æ ‡é¢˜
    plt.suptitle('ğŸ  Roof Detection Results Overview - 50 Images Analysis', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    summary_path = output_dir / "detection_summary_50_images.png"
    plt.savefig(summary_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… Extended summary saved: {summary_path}")
    return summary_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ Roof Detection Visualization - 50 Images Extended")
    print("=" * 60)
    
    # è®¾ç½®è·¯å¾„
    # ç›´æ¥ä½¿ç”¨è®­ç»ƒå›¾ç‰‡ç›®å½•
    train_images_dir = Path("data/raw/new-2-1/train/images")
    output_dir = Path("visualization_results_50")
    output_dir.mkdir(exist_ok=True)
    
    if not train_images_dir.exists():
        print(f"âŒ Training images directory not found: {train_images_dir}")
        return

    # åŠ è½½æ¨¡å‹
    model, model_path = load_best_model()
    if model is None:
        return

    # ç›´æ¥ä»è®­ç»ƒå›¾ç‰‡ç›®å½•é€‰æ‹©50å¼ å›¾ç‰‡
    all_images = list(train_images_dir.glob("*.jpg"))
    if len(all_images) < 50:
        print(f"âš ï¸ Only found {len(all_images)} images, using all available")
        test_images = all_images
    else:
        import random
        random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
        test_images = random.sample(all_images, 50)

    if not test_images:
        print("âŒ No images found")
        return
    
    print(f"\nğŸš€ Processing {len(test_images)} images...")
    
    # æ‰¹é‡å¤„ç†å›¾ç‰‡
    results_data = predict_and_visualize_batch(model, test_images, output_dir)
    
    # åˆ›å»ºæ€»è§ˆ
    if results_data:
        summary_path = create_extended_summary(results_data, output_dir)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_json = {
            'model_path': model_path,
            'timestamp': datetime.now().isoformat(),
            'total_images': len(results_data),
            'total_detections': sum(r['num_detections'] for r in results_data),
            'results': results_data
        }
        
        json_path = output_dir / "detection_results_50.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_json, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ‰ 50 Images Visualization completed!")
        print(f"ğŸ“ Results saved in: {output_dir}")
        print(f"ğŸ“Š Summary chart: {summary_path}")
        print(f"ğŸ“‹ Detailed results: {json_path}")
        print(f"ğŸ–¼ï¸ Processed images: {len(results_data)}/50")
        print(f"ğŸ¯ Total detections: {sum(r['num_detections'] for r in results_data)}")
        
        # æ˜¾ç¤ºç±»åˆ«ç»Ÿè®¡
        class_counts = {}
        for result in results_data:
            for detection in result['detections']:
                class_name = detection['class']
                if class_name not in class_counts:
                    class_counts[class_name] = 0
                class_counts[class_name] += 1
        
        print(f"\nğŸ“‹ Class Detection Statistics:")
        for class_name, count in class_counts.items():
            print(f"   {class_name}: {count}")
    
    else:
        print("âŒ No images processed successfully")

if __name__ == "__main__":
    main()
