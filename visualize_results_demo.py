#!/usr/bin/env python3
"""
å¯è§†åŒ–ç»“æœæ¼”ç¤ºè„šæœ¬
Visualization Results Demo Script

é€‰å–20ç»„å›¾ç‰‡è¿›è¡Œæ¨ç†å¹¶ç”Ÿæˆå¯è§†åŒ–ç»“æœ
"""

import os
import random
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import json
from datetime import datetime

def find_test_images(data_yaml_path, num_images=20):
    """ä»æ•°æ®é›†ä¸­é€‰å–æµ‹è¯•å›¾ç‰‡"""

    print("ğŸ” æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡...")

    # è¯»å–æ•°æ®é›†é…ç½®
    import yaml
    with open(data_yaml_path) as f:
        config = yaml.safe_load(f)

    # è·å–æ•°æ®é›†æ ¹ç›®å½•
    dataset_root = Path(data_yaml_path).parent

    # æŸ¥æ‰¾éªŒè¯é›†å›¾ç‰‡
    val_images_dir = dataset_root / "val" / "images"
    train_images_dir = dataset_root / "train" / "images"

    # æ”¶é›†æ‰€æœ‰å›¾ç‰‡
    image_files = []

    # ä¼˜å…ˆä½¿ç”¨éªŒè¯é›†
    if val_images_dir.exists():
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(list(val_images_dir.glob(ext)))
            image_files.extend(list(val_images_dir.glob(ext.upper())))

    # å¦‚æœéªŒè¯é›†å›¾ç‰‡ä¸å¤Ÿï¼Œä»è®­ç»ƒé›†è¡¥å……
    if len(image_files) < num_images and train_images_dir.exists():
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            train_files = list(train_images_dir.glob(ext))
            train_files.extend(list(train_images_dir.glob(ext.upper())))
            image_files.extend(train_files)

    if len(image_files) == 0:
        print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return []

    # éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„å›¾ç‰‡
    selected_images = random.sample(image_files, min(num_images, len(image_files)))

    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡ï¼Œé€‰æ‹©äº† {len(selected_images)} å¼ ")

    return selected_images

def load_best_model():
    """åŠ è½½æœ€ä½³è®­ç»ƒæ¨¡å‹"""

    print("ğŸ”§ åŠ è½½æœ€ä½³æ¨¡å‹...")

    # å°è¯•åŠ è½½ç»§ç»­è®­ç»ƒçš„æœ€ä½³æ¨¡å‹
    model_paths = [
        "runs/segment/continue_training_optimized/weights/best.pt",
        "runs/segment/improved_training_compatible/weights/best.pt",
        "models/pretrained/yolov8l-seg.pt"
    ]

    for model_path in model_paths:
        if os.path.exists(model_path):
            print(f"âœ… åŠ è½½æ¨¡å‹: {model_path}")
            model = YOLO(model_path)
            return model, model_path

    print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
    return None, None

def predict_and_visualize(model, image_path, output_dir, image_index):
    """å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œæ¨ç†å¹¶å¯è§†åŒ–"""

    # æ‰§è¡Œæ¨ç†
    results = model.predict(
        source=str(image_path),
        conf=0.35,
        iou=0.6,
        imgsz=896,
        save=False,
        verbose=False
    )[0]

    # è¯»å–åŸå›¾
    image = cv2.imread(str(image_path))
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
    annotated_image = results.plot()
    annotated_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)

    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, axes = plt.subplots(1, 2, figsize=(20, 10))

    # åŸå›¾
    axes[0].imshow(image_rgb)
    axes[0].set_title(f'åŸå›¾ {image_index+1}: {image_path.name}', fontsize=14, fontweight='bold')
    axes[0].axis('off')

    # æ£€æµ‹ç»“æœ
    axes[1].imshow(annotated_rgb)

    # ç»Ÿè®¡æ£€æµ‹ç»“æœ
    num_detections = len(results.boxes) if results.boxes else 0
    detection_info = []

    if results.boxes:
        class_counts = {}
        for box in results.boxes:
            class_id = int(box.cls[0])
            class_name = results.names[class_id]
            confidence = float(box.conf[0])

            if class_name not in class_counts:
                class_counts[class_name] = 0
            class_counts[class_name] += 1

            detection_info.append({
                'class': class_name,
                'confidence': confidence,
                'bbox': box.xyxy[0].tolist()
            })

        # ç”Ÿæˆæ ‡é¢˜
        title_parts = [f'æ£€æµ‹ç»“æœ (å…±{num_detections}ä¸ªç›®æ ‡)']
        for class_name, count in class_counts.items():
            title_parts.append(f'{class_name}: {count}ä¸ª')

        title = '\n'.join(title_parts)
    else:
        title = 'æ£€æµ‹ç»“æœ (æœªæ£€æµ‹åˆ°ç›®æ ‡)'

    axes[1].set_title(title, fontsize=14, fontweight='bold')
    axes[1].axis('off')

    plt.tight_layout()

    # ä¿å­˜å¯¹æ¯”å›¾
    output_path = output_dir / f"result_{image_index+1:02d}_{image_path.stem}.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    # ä¿å­˜å•ç‹¬çš„æ£€æµ‹ç»“æœ
    result_only_path = output_dir / f"detection_{image_index+1:02d}_{image_path.stem}.jpg"
    cv2.imwrite(str(result_only_path), annotated_image)

    return {
        'image_path': str(image_path),
        'output_path': str(output_path),
        'result_only_path': str(result_only_path),
        'num_detections': num_detections,
        'detections': detection_info,
        'image_size': image.shape[:2]
    }

def create_summary_visualization(results_data, output_dir):
    """åˆ›å»ºç»“æœæ€»è§ˆå¯è§†åŒ–"""

    print("ğŸ“Š åˆ›å»ºç»“æœæ€»è§ˆ...")

    # ç»Ÿè®¡æ€»ä½“ç»“æœ
    total_images = len(results_data)
    total_detections = sum(r['num_detections'] for r in results_data)

    # ç»Ÿè®¡å„ç±»åˆ«æ£€æµ‹æ•°é‡
    class_counts = {}
    confidence_scores = []

    for result in results_data:
        for detection in result['detections']:
            class_name = detection['class']
            confidence = detection['confidence']

            if class_name not in class_counts:
                class_counts[class_name] = 0
            class_counts[class_name] += 1
            confidence_scores.append(confidence)

    # åˆ›å»ºç»Ÿè®¡å›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. æ¯å¼ å›¾ç‰‡çš„æ£€æµ‹æ•°é‡
    image_indices = range(1, total_images + 1)
    detection_counts = [r['num_detections'] for r in results_data]

    axes[0, 0].bar(image_indices, detection_counts, color='skyblue', alpha=0.7)
    axes[0, 0].set_title('æ¯å¼ å›¾ç‰‡çš„æ£€æµ‹æ•°é‡', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('å›¾ç‰‡ç¼–å·')
    axes[0, 0].set_ylabel('æ£€æµ‹æ•°é‡')
    axes[0, 0].grid(True, alpha=0.3)

    # 2. ç±»åˆ«åˆ†å¸ƒ
    if class_counts:
        classes = list(class_counts.keys())
        counts = list(class_counts.values())
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']

        axes[0, 1].pie(counts, labels=classes, autopct='%1.1f%%',
                       colors=colors[:len(classes)], startangle=90)
        axes[0, 1].set_title('ç±»åˆ«åˆ†å¸ƒ', fontsize=14, fontweight='bold')

    # 3. ç½®ä¿¡åº¦åˆ†å¸ƒ
    if confidence_scores:
        axes[1, 0].hist(confidence_scores, bins=20, color='lightgreen', alpha=0.7, edgecolor='black')
        axes[1, 0].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('ç½®ä¿¡åº¦')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].grid(True, alpha=0.3)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_conf = np.mean(confidence_scores)
        axes[1, 0].axvline(mean_conf, color='red', linestyle='--',
                          label=f'å¹³å‡ç½®ä¿¡åº¦: {mean_conf:.3f}')
        axes[1, 0].legend()

    # 4. æ€»ä½“ç»Ÿè®¡
    axes[1, 1].axis('off')
    stats_text = f"""
ğŸ“Š æ£€æµ‹ç»“æœæ€»è§ˆ

ğŸ–¼ï¸ æ€»å›¾ç‰‡æ•°: {total_images}
ğŸ¯ æ€»æ£€æµ‹æ•°: {total_detections}
ğŸ“ˆ å¹³å‡æ¯å›¾: {total_detections/total_images:.1f}ä¸ªç›®æ ‡

ğŸ“‹ ç±»åˆ«ç»Ÿè®¡:
"""

    for class_name, count in class_counts.items():
        percentage = (count / total_detections) * 100 if total_detections > 0 else 0
        stats_text += f"   {class_name}: {count}ä¸ª ({percentage:.1f}%)\n"

    if confidence_scores:
        stats_text += f"\nğŸ¯ ç½®ä¿¡åº¦ç»Ÿè®¡:\n"
        stats_text += f"   å¹³å‡: {np.mean(confidence_scores):.3f}\n"
        stats_text += f"   æœ€é«˜: {np.max(confidence_scores):.3f}\n"
        stats_text += f"   æœ€ä½: {np.min(confidence_scores):.3f}\n"

    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes,
                    fontsize=12, verticalalignment='top',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.5))

    plt.suptitle('ğŸ  å±‹é¡¶æ£€æµ‹ç»“æœæ€»è§ˆ - 20å¼ å›¾ç‰‡å¯è§†åŒ–åˆ†æ', fontsize=16, fontweight='bold')
    plt.tight_layout()

    # ä¿å­˜æ€»è§ˆå›¾
    summary_path = output_dir / "detection_summary.png"
    plt.savefig(summary_path, dpi=300, bbox_inches='tight')
    plt.close()

    return str(summary_path)

def main():
    """ä¸»å‡½æ•°"""

    print("ğŸ¨ å±‹é¡¶æ£€æµ‹å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 50)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("visualization_results")
    output_dir.mkdir(exist_ok=True)

    # æ•°æ®é›†é…ç½®
    data_yaml = "data/raw/new-2-1/data.yaml"

    if not os.path.exists(data_yaml):
        print(f"âŒ æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
        return

    # åŠ è½½æ¨¡å‹
    model, model_path = load_best_model()
    if model is None:
        return

    # é€‰æ‹©æµ‹è¯•å›¾ç‰‡
    test_images = find_test_images(data_yaml, num_images=20)
    if not test_images:
        return

    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(test_images)} å¼ å›¾ç‰‡...")

    # å¤„ç†æ¯å¼ å›¾ç‰‡
    results_data = []

    for i, image_path in enumerate(test_images):
        print(f"ğŸ” å¤„ç†å›¾ç‰‡ {i+1}/20: {image_path.name}")

        try:
            result = predict_and_visualize(model, image_path, output_dir, i)
            results_data.append(result)
            print(f"   âœ… æ£€æµ‹åˆ° {result['num_detections']} ä¸ªç›®æ ‡")

        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
            continue

    # åˆ›å»ºæ€»è§ˆ
    if results_data:
        summary_path = create_summary_visualization(results_data, output_dir)

        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_json = {
            'model_path': model_path,
            'timestamp': datetime.now().isoformat(),
            'total_images': len(results_data),
            'total_detections': sum(r['num_detections'] for r in results_data),
            'results': results_data
        }

        json_path = output_dir / "detection_results.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_json, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        print(f"ğŸ“Š æ€»è§ˆå›¾: {summary_path}")
        print(f"ğŸ“‹ è¯¦ç»†ç»“æœ: {json_path}")
        print(f"ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡: {len(results_data)}/20")
        print(f"ğŸ¯ æ€»æ£€æµ‹æ•°: {sum(r['num_detections'] for r in results_data)}")

        # æ˜¾ç¤ºç±»åˆ«ç»Ÿè®¡
        class_counts = {}
        for result in results_data:
            for detection in result['detections']:
                class_name = detection['class']
                if class_name not in class_counts:
                    class_counts[class_name] = 0
                class_counts[class_name] += 1

        print(f"\nğŸ“‹ ç±»åˆ«æ£€æµ‹ç»Ÿè®¡:")
        for class_name, count in class_counts.items():
            print(f"   {class_name}: {count}ä¸ª")

    else:
        print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å›¾ç‰‡")

if __name__ == "__main__":
    main()