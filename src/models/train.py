"""
æ¨¡å‹è®­ç»ƒæ¨¡å— - ä¸“å®¶æ”¹è¿›ç‰ˆ
Model training module - Expert improved version

æ”¯æŒä¸“å®¶æ”¹è¿›çš„æ‰€æœ‰åŠŸèƒ½ï¼š
- è‡ªåŠ¨ç±»åˆ«æƒé‡è®¡ç®—
- ç»Ÿä¸€è§£åƒåº¦
- ä½™å¼¦é€€ç«å­¦ä¹ ç‡
- åˆ†å‰²å‹å¥½æ•°æ®å¢å¼º
"""

import os
import glob
import yaml
import logging
import numpy as np
from pathlib import Path
from typing import Dict, Optional, Any, List
from collections import Counter
from ultralytics import YOLO

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RoofDetectionTrainer:
    """å±‹é¡¶æ£€æµ‹æ¨¡å‹è®­ç»ƒå™¨ - ä¸“å®¶æ”¹è¿›ç‰ˆ"""

    def __init__(self, config_path: str = "config/model_config.yaml"):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            config_path: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.model = None
        self.class_weights = None
        self.class_names = None
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r') as f:
                config = yaml.safe_load(f)
            logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise
    
    def calculate_class_weights(self, data_yaml: str) -> np.ndarray:
        """
        ä¸“å®¶æ”¹è¿›1: è‡ªåŠ¨è®¡ç®—ç±»åˆ«æƒé‡
        ä½¿ç”¨æœ‰æ•ˆæ ·æœ¬æ•°æ–¹æ³• (Cui et al., 2019)

        Args:
            data_yaml: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            è®¡ç®—å¾—åˆ°çš„ç±»åˆ«æƒé‡æ•°ç»„
        """
        try:
            # è¯»å–æ•°æ®é…ç½®
            with open(data_yaml, 'r') as f:
                data_config = yaml.safe_load(f)

            self.class_names = data_config['names']
            num_classes = data_config['nc']

            # è·å–è®­ç»ƒæ•°æ®è·¯å¾„
            train_path = data_config['train']
            if os.path.isfile(train_path):
                train_dir = os.path.dirname(train_path)
            else:
                train_dir = train_path

            # æŸ¥æ‰¾æ ‡ç­¾æ–‡ä»¶
            label_dir = os.path.join(os.path.dirname(train_dir), 'labels') if 'images' in train_dir else os.path.join(train_dir, 'labels')
            label_files = glob.glob(os.path.join(label_dir, '*.txt'))

            if not label_files:
                logger.warning("æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æƒé‡")
                return np.ones(num_classes)

            # ç»Ÿè®¡å„ç±»åˆ«å®ä¾‹æ•°
            counter = Counter()
            for f in label_files:
                with open(f) as r:
                    for line in r:
                        if line.strip():
                            cls_id = int(line.split()[0])
                            counter[cls_id] += 1

            logger.info("ğŸ“Š ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:")
            for i in range(num_classes):
                count = counter.get(i, 0)
                logger.info(f"   {self.class_names[i]:12}: {count:6d} ä¸ªå®ä¾‹")

            # æœ‰æ•ˆæ ·æœ¬æ•°æ–¹æ³•è®¡ç®—æƒé‡
            beta = 0.999
            freq = np.array([counter.get(i, 0) for i in range(num_classes)], dtype=float)
            freq = np.maximum(freq, 1)  # é¿å…é™¤é›¶

            eff_num = 1 - np.power(beta, freq)
            cls_weights = (1 - beta) / eff_num
            cls_weights = cls_weights / cls_weights.mean()  # å½’ä¸€åŒ–

            logger.info("ğŸ¯ è‡ªåŠ¨è®¡ç®—çš„ç±»åˆ«æƒé‡:")
            for i, (name, weight) in enumerate(zip(self.class_names, cls_weights)):
                logger.info(f"   {name:12}: {weight:.3f}")

            self.class_weights = cls_weights
            return cls_weights

        except Exception as e:
            logger.error(f"ç±»åˆ«æƒé‡è®¡ç®—å¤±è´¥: {e}")
            return np.ones(num_classes)

    def load_model(self, model_path: Optional[str] = None) -> None:
        """
        åŠ è½½æ¨¡å‹

        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
        """
        try:
            if model_path is None:
                model_path = self.config['model']['name']

            self.model = YOLO(model_path)
            logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")

        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def train(
        self,
        data_yaml: str = "config/data.yaml",
        project: str = "runs/segment",
        name: str = "train_expert_local",
        use_expert_improvements: bool = True,
        **kwargs
    ) -> Any:
        """
        è®­ç»ƒæ¨¡å‹ - ä¸“å®¶æ”¹è¿›ç‰ˆ

        Args:
            data_yaml: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
            project: é¡¹ç›®ä¿å­˜è·¯å¾„
            name: è®­ç»ƒä»»åŠ¡åç§°
            use_expert_improvements: æ˜¯å¦ä½¿ç”¨ä¸“å®¶æ”¹è¿›
            **kwargs: å…¶ä»–è®­ç»ƒå‚æ•°

        Returns:
            è®­ç»ƒç»“æœ
        """
        if self.model is None:
            self.load_model()

        # è·å–è®­ç»ƒé…ç½®
        train_config = self.config['training'].copy()

        # ä¸“å®¶æ”¹è¿›é…ç½®
        if use_expert_improvements:
            logger.info("ğŸ¯ å¯ç”¨ä¸“å®¶æ”¹è¿›åŠŸèƒ½...")

            # ä¸“å®¶æ”¹è¿›1: è‡ªåŠ¨è®¡ç®—ç±»åˆ«æƒé‡
            class_weights = self.calculate_class_weights(data_yaml)
            train_config['class_weights'] = class_weights.tolist()

            # ä¸“å®¶æ”¹è¿›2: ç»Ÿä¸€è§£åƒåº¦
            IMG_SIZE = 768
            train_config['imgsz'] = IMG_SIZE
            logger.info(f"ğŸ“ ç»Ÿä¸€è§£åƒåº¦: {IMG_SIZE}x{IMG_SIZE}")

            # ä¸“å®¶æ”¹è¿›3: ç°ä»£å­¦ä¹ ç‡ç­–ç•¥
            train_config.update({
                'optimizer': 'AdamW',
                'lr0': 2e-4,
                'cos_lr': True,
                'warmup_epochs': 5,
                'warmup_momentum': 0.8,
                'warmup_bias_lr': 0.1,
            })
            logger.info("ğŸ”„ å¯ç”¨ä½™å¼¦é€€ç« + AdamW")

            # ä¸“å®¶æ”¹è¿›4: åˆ†å‰²å‹å¥½æ•°æ®å¢å¼º
            train_config.update({
                'mosaic': 0.25,      # å¤§å¹…é™ä½
                'copy_paste': 0.5,   # åˆ†å‰²ä¸“ç”¨å¢å¼º
                'close_mosaic': 0,   # ä¸å»¶è¿Ÿå…³é—­
                'mixup': 0.0,
                'hsv_h': 0.02,
                'hsv_s': 0.7,
                'hsv_v': 0.4,
                'degrees': 10.0,
                'translate': 0.1,
                'scale': 0.5,
                'shear': 0.0,
                'perspective': 0.0,
                'flipud': 0.5,
                'fliplr': 0.5,
            })
            logger.info("ğŸ¨ å¯ç”¨åˆ†å‰²å‹å¥½æ•°æ®å¢å¼º")

            # ä¸“å®¶æ”¹è¿›5: è®­ç»ƒæ§åˆ¶ä¼˜åŒ–
            train_config.update({
                'patience': 20,
                'save_period': -1,
                'amp': True,
            })

            logger.info("âœ… ä¸“å®¶æ”¹è¿›é…ç½®å®Œæˆ")

        # åº”ç”¨ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°
        train_config.update(kwargs)

        # ç¡®ä¿æ•°æ®é…ç½®æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(data_yaml):
            logger.error(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
            raise FileNotFoundError(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")

        try:
            logger.info("ğŸš€ å¼€å§‹ä¸“å®¶æ”¹è¿›ç‰ˆè®­ç»ƒ...")
            logger.info(f"æ•°æ®é…ç½®: {data_yaml}")
            logger.info(f"é¡¹ç›®è·¯å¾„: {project}/{name}")

            if use_expert_improvements:
                logger.info("ğŸ¯ ä¸“å®¶æ”¹è¿›æ‘˜è¦:")
                logger.info(f"   è‡ªåŠ¨ç±»åˆ«æƒé‡: {[f'{w:.3f}' for w in class_weights]}")
                logger.info(f"   ç»Ÿä¸€è§£åƒåº¦: {train_config['imgsz']}")
                logger.info(f"   å­¦ä¹ ç‡ç­–ç•¥: {train_config['optimizer']} + ä½™å¼¦é€€ç«")
                logger.info(f"   æ•°æ®å¢å¼º: Mosaic={train_config['mosaic']}, Copy-Paste={train_config['copy_paste']}")

            # å¼€å§‹è®­ç»ƒ
            results = self.model.train(
                data=data_yaml,
                project=project,
                name=name,
                **train_config
            )

            logger.info("ğŸ‰ ä¸“å®¶æ”¹è¿›ç‰ˆè®­ç»ƒå®Œæˆ!")
            return results

        except Exception as e:
            logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
            raise
    
    def get_best_model_path(self, project: str = "runs/segment", name: str = "train_improved") -> str:
        """è·å–æœ€ä½³æ¨¡å‹è·¯å¾„"""
        return os.path.join(project, name, "weights", "best.pt")
    
    def validate_training_setup(self, data_yaml: str = "config/data.yaml") -> bool:
        """
        éªŒè¯è®­ç»ƒè®¾ç½®
        
        Args:
            data_yaml: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
        """
        try:
            # æ£€æŸ¥æ•°æ®é…ç½®æ–‡ä»¶
            if not os.path.exists(data_yaml):
                logger.error(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
                return False
            
            # æ£€æŸ¥æ•°æ®é…ç½®å†…å®¹
            with open(data_yaml, 'r') as f:
                data_config = yaml.safe_load(f)
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['train', 'val', 'nc', 'names']
            for field in required_fields:
                if field not in data_config:
                    logger.error(f"æ•°æ®é…ç½®ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥ç±»åˆ«æƒé‡ï¼ˆå…³é”®æ”¹è¿›ï¼‰
            if 'class_weights' not in data_config:
                logger.warning("æ•°æ®é…ç½®ä¸­æœªæ‰¾åˆ°class_weightsï¼Œè¿™å¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
            else:
                logger.info(f"âœ… å‘ç°ç±»åˆ«æƒé‡è®¾ç½®: {data_config['class_weights']}")
            
            # æ£€æŸ¥æ•°æ®è·¯å¾„
            for split in ['train', 'val']:
                path = data_config[split]
                if not os.path.exists(path):
                    logger.error(f"{split}æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {path}")
                    return False
            
            logger.info("âœ… è®­ç»ƒè®¾ç½®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"è®­ç»ƒè®¾ç½®éªŒè¯å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è®­ç»ƒå±‹é¡¶æ£€æµ‹æ¨¡å‹")
    parser.add_argument("--config", default="config/model_config.yaml", help="æ¨¡å‹é…ç½®æ–‡ä»¶")
    parser.add_argument("--data", default="config/data.yaml", help="æ•°æ®é…ç½®æ–‡ä»¶")
    parser.add_argument("--project", default="runs/segment", help="é¡¹ç›®ä¿å­˜è·¯å¾„")
    parser.add_argument("--name", default="train_improved", help="è®­ç»ƒä»»åŠ¡åç§°")
    parser.add_argument("--epochs", type=int, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch", type=int, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--lr0", type=float, help="åˆå§‹å­¦ä¹ ç‡")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = RoofDetectionTrainer(args.config)
    
    # éªŒè¯è®¾ç½®
    if not trainer.validate_training_setup(args.data):
        logger.error("è®­ç»ƒè®¾ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # å‡†å¤‡è®­ç»ƒå‚æ•°
    train_kwargs = {}
    if args.epochs:
        train_kwargs['epochs'] = args.epochs
    if args.batch:
        train_kwargs['batch'] = args.batch
    if args.lr0:
        train_kwargs['lr0'] = args.lr0
    
    # å¼€å§‹è®­ç»ƒ
    try:
        results = trainer.train(
            data_yaml=args.data,
            project=args.project,
            name=args.name,
            **train_kwargs
        )
        
        # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹è·¯å¾„
        best_model = trainer.get_best_model_path(args.project, args.name)
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æœ€ä½³æ¨¡å‹è·¯å¾„: {best_model}")
        print(f"ğŸ“Š æŸ¥çœ‹ç»“æœ: {os.path.join(args.project, args.name)}")
        
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
