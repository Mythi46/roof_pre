#!/usr/bin/env python3
"""
ç”Ÿæˆä¸“å®¶æ”¹è¿›ç‰ˆå¯è§†åŒ–ç»“æœ
Generate expert improved version visualization results

åˆ›å»º20ä¸ªå¯è§†åŒ–ä¾‹å­å±•ç¤ºè®­ç»ƒæ•ˆæœ
"""

import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pathlib import Path
import random
from ultralytics import YOLO
import yaml

# è®¾ç½®matplotlibä½¿ç”¨è‹±æ–‡æ˜¾ç¤ºï¼Œé¿å…ä¹±ç é—®é¢˜
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
print("âœ… è®¾ç½®å›¾è¡¨ä½¿ç”¨è‹±æ–‡æ˜¾ç¤º")

print("ğŸ¨ ç”Ÿæˆä¸“å®¶æ”¹è¿›ç‰ˆå¯è§†åŒ–ç»“æœ")
print("=" * 50)

# é…ç½®
BEST_MODEL_PATH = "runs/segment/expert_no_class_weights/weights/best.pt"
DATA_YAML = "new-2-1/data.yaml"
OUTPUT_DIR = "expert_visualization_results"
NUM_EXAMPLES = 20

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
if not os.path.exists(BEST_MODEL_PATH):
    print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {BEST_MODEL_PATH}")
    print("ğŸ’¡ è¯·å…ˆå®Œæˆè®­ç»ƒ")
    sys.exit(1)

print(f"âœ… æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {BEST_MODEL_PATH}")

# è¯»å–æ•°æ®é…ç½®
with open(DATA_YAML, 'r') as f:
    data_config = yaml.safe_load(f)

class_names = data_config['names']
print(f"ğŸ“Š ç±»åˆ«: {class_names}")

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(f"{OUTPUT_DIR}/predictions", exist_ok=True)
os.makedirs(f"{OUTPUT_DIR}/comparisons", exist_ok=True)
os.makedirs(f"{OUTPUT_DIR}/detailed_analysis", exist_ok=True)

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
print("ğŸ”§ åŠ è½½ä¸“å®¶æ”¹è¿›ç‰ˆæ¨¡å‹...")
model = YOLO(BEST_MODEL_PATH)
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# è·å–éªŒè¯é›†å›¾åƒ
val_images_dir = os.path.join(os.path.dirname(DATA_YAML), "valid", "images")
val_labels_dir = os.path.join(os.path.dirname(DATA_YAML), "valid", "labels")

if not os.path.exists(val_images_dir):
    print(f"âŒ éªŒè¯é›†å›¾åƒç›®å½•ä¸å­˜åœ¨: {val_images_dir}")
    sys.exit(1)

# è·å–æ‰€æœ‰éªŒè¯å›¾åƒ
image_files = [f for f in os.listdir(val_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
print(f"ğŸ“¸ æ‰¾åˆ° {len(image_files)} å¼ éªŒè¯å›¾åƒ")

# éšæœºé€‰æ‹©20å¼ å›¾åƒ
selected_images = random.sample(image_files, min(NUM_EXAMPLES, len(image_files)))
print(f"ğŸ¯ é€‰æ‹© {len(selected_images)} å¼ å›¾åƒè¿›è¡Œå¯è§†åŒ–")

# é¢œè‰²æ˜ å°„
colors = [
    (255, 0, 0),    # Baren-Land - çº¢è‰²
    (0, 255, 0),    # farm - ç»¿è‰²  
    (0, 0, 255),    # rice-fields - è“è‰²
    (255, 255, 0),  # roof - é»„è‰²
]

def load_ground_truth(label_file, img_shape):
    """åŠ è½½çœŸå®æ ‡ç­¾"""
    if not os.path.exists(label_file):
        return []
    
    h, w = img_shape[:2]
    gt_boxes = []
    
    with open(label_file, 'r') as f:
        for line in f:
            if line.strip():
                parts = line.strip().split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1]) * w
                    y_center = float(parts[2]) * h
                    width = float(parts[3]) * w
                    height = float(parts[4]) * h
                    
                    x1 = int(x_center - width/2)
                    y1 = int(y_center - height/2)
                    x2 = int(x_center + width/2)
                    y2 = int(y_center + height/2)
                    
                    gt_boxes.append({
                        'class': cls_id,
                        'bbox': [x1, y1, x2, y2],
                        'confidence': 1.0
                    })
    
    return gt_boxes

def create_visualization(image_path, predictions, ground_truth, output_path, image_name):
    """åˆ›å»ºå¯è§†åŒ–ç»“æœ"""
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'Expert Improved Model Analysis - {image_name}', fontsize=16, fontweight='bold')

    # 1. Original Image
    axes[0,0].imshow(image_rgb)
    axes[0,0].set_title('Original Image', fontsize=14)
    axes[0,0].axis('off')

    # 2. Ground Truth
    axes[0,1].imshow(image_rgb)
    axes[0,1].set_title('Ground Truth Labels', fontsize=14)
    for gt in ground_truth:
        x1, y1, x2, y2 = gt['bbox']
        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, 
                               linewidth=2, edgecolor=np.array(colors[gt['class']])/255, 
                               facecolor='none', linestyle='--')
        axes[0,1].add_patch(rect)
        axes[0,1].text(x1, y1-5, class_names[gt['class']], 
                      color=np.array(colors[gt['class']])/255, fontsize=10, fontweight='bold')
    axes[0,1].axis('off')
    
    # 3. Prediction Results
    axes[1,0].imshow(image_rgb)
    axes[1,0].set_title('Expert Model Predictions', fontsize=14)
    
    if predictions and len(predictions.boxes) > 0:
        boxes = predictions.boxes.xyxy.cpu().numpy()
        classes = predictions.boxes.cls.cpu().numpy().astype(int)
        confidences = predictions.boxes.conf.cpu().numpy()
        
        for box, cls, conf in zip(boxes, classes, confidences):
            if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                x1, y1, x2, y2 = box.astype(int)
                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, 
                                       linewidth=2, edgecolor=np.array(colors[cls])/255, 
                                       facecolor='none')
                axes[1,0].add_patch(rect)
                axes[1,0].text(x1, y1-5, f'{class_names[cls]} {conf:.2f}', 
                              color=np.array(colors[cls])/255, fontsize=10, fontweight='bold')
    axes[1,0].axis('off')
    
    # 4. Comparison Analysis
    axes[1,1].imshow(image_rgb)
    axes[1,1].set_title('Analysis (Green=Correct, Red=Wrong, Blue=Missed)', fontsize=14)
    
    # ç»˜åˆ¶çœŸå®æ ‡ç­¾ï¼ˆè“è‰²è™šçº¿ï¼‰
    for gt in ground_truth:
        x1, y1, x2, y2 = gt['bbox']
        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, 
                               linewidth=2, edgecolor='blue', 
                               facecolor='none', linestyle='--', alpha=0.7)
        axes[1,1].add_patch(rect)
    
    # ç»˜åˆ¶é¢„æµ‹ç»“æœï¼ˆæ ¹æ®æ­£ç¡®æ€§ç€è‰²ï¼‰
    if predictions and len(predictions.boxes) > 0:
        boxes = predictions.boxes.xyxy.cpu().numpy()
        classes = predictions.boxes.cls.cpu().numpy().astype(int)
        confidences = predictions.boxes.conf.cpu().numpy()
        
        for box, cls, conf in zip(boxes, classes, confidences):
            if conf > 0.5:
                x1, y1, x2, y2 = box.astype(int)
                
                # ç®€å•çš„æ­£ç¡®æ€§åˆ¤æ–­ï¼ˆåŸºäºIoUï¼‰
                is_correct = False
                for gt in ground_truth:
                    gt_x1, gt_y1, gt_x2, gt_y2 = gt['bbox']
                    # è®¡ç®—IoU
                    intersection = max(0, min(x2, gt_x2) - max(x1, gt_x1)) * max(0, min(y2, gt_y2) - max(y1, gt_y1))
                    union = (x2-x1)*(y2-y1) + (gt_x2-gt_x1)*(gt_y2-gt_y1) - intersection
                    iou = intersection / union if union > 0 else 0
                    
                    if iou > 0.5 and cls == gt['class']:
                        is_correct = True
                        break
                
                color = 'green' if is_correct else 'red'
                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, 
                                       linewidth=2, edgecolor=color, facecolor='none')
                axes[1,1].add_patch(rect)
    
    axes[1,1].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

# ç”Ÿæˆå¯è§†åŒ–ç»“æœ
print("\nğŸ¨ å¼€å§‹ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")

for i, image_file in enumerate(selected_images, 1):
    print(f"ğŸ“¸ å¤„ç†å›¾åƒ {i}/{len(selected_images)}: {image_file}")
    
    # å›¾åƒè·¯å¾„
    image_path = os.path.join(val_images_dir, image_file)
    label_file = os.path.join(val_labels_dir, image_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))
    
    # åŠ è½½å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âš ï¸ æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
        continue
    
    # è¿è¡Œé¢„æµ‹
    try:
        results = model(image_path, conf=0.25, iou=0.45)
        predictions = results[0] if results else None
    except Exception as e:
        print(f"âš ï¸ é¢„æµ‹å¤±è´¥: {e}")
        predictions = None
    
    # åŠ è½½çœŸå®æ ‡ç­¾
    ground_truth = load_ground_truth(label_file, image.shape)
    
    # åˆ›å»ºå¯è§†åŒ–
    output_path = os.path.join(OUTPUT_DIR, "predictions", f"example_{i:02d}_{image_file.split('.')[0]}.png")
    create_visualization(image_path, predictions, ground_truth, output_path, image_file)
    
    print(f"âœ… ä¿å­˜: {output_path}")

# åˆ›å»ºæ€»ç»“æŠ¥å‘Š
print("\nğŸ“Š åˆ›å»ºæ€»ç»“æŠ¥å‘Š...")

summary_report = f"""# ğŸ¨ ä¸“å®¶æ”¹è¿›ç‰ˆå¯è§†åŒ–ç»“æœæ€»ç»“

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- **æ¨¡å‹**: {BEST_MODEL_PATH}
- **æ•°æ®é›†**: {DATA_YAML}
- **ç”Ÿæˆæ—¶é—´**: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ ·æœ¬æ•°é‡**: {len(selected_images)}

## ğŸ¯ ç±»åˆ«ä¿¡æ¯
"""

for i, name in enumerate(class_names):
    color_rgb = colors[i]
    summary_report += f"- **{name}**: RGB{color_rgb}\n"

summary_report += f"""

## ğŸ“ æ–‡ä»¶ç»“æ„
```
{OUTPUT_DIR}/
â”œâ”€â”€ predictions/           # 20ä¸ªé¢„æµ‹ç»“æœå¯è§†åŒ–
â”‚   â”œâ”€â”€ example_01_*.png
â”‚   â”œâ”€â”€ example_02_*.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ comparisons/          # å¯¹æ¯”åˆ†æï¼ˆé¢„ç•™ï¼‰
â”œâ”€â”€ detailed_analysis/    # è¯¦ç»†åˆ†æï¼ˆé¢„ç•™ï¼‰
â””â”€â”€ README.md            # æœ¬æ–‡ä»¶
```

## ğŸ¨ å¯è§†åŒ–è¯´æ˜

æ¯ä¸ªå¯è§†åŒ–å›¾åƒåŒ…å«4ä¸ªå­å›¾ï¼š

1. **åŸå§‹å›¾åƒ** - è¾“å…¥çš„å«æ˜Ÿå›¾åƒ
2. **çœŸå®æ ‡ç­¾** - Ground Truthæ ‡æ³¨ï¼ˆè™šçº¿æ¡†ï¼‰
3. **ä¸“å®¶æ”¹è¿›ç‰ˆé¢„æµ‹** - æ¨¡å‹é¢„æµ‹ç»“æœï¼ˆå®çº¿æ¡† + ç½®ä¿¡åº¦ï¼‰
4. **å¯¹æ¯”åˆ†æ** - æ­£ç¡®æ€§åˆ†æ
   - ğŸŸ¢ ç»¿è‰²æ¡†: æ­£ç¡®é¢„æµ‹
   - ğŸ”´ çº¢è‰²æ¡†: é”™è¯¯é¢„æµ‹  
   - ğŸ”µ è“è‰²è™šçº¿: çœŸå®æ ‡ç­¾

## ğŸ¯ ä¸“å®¶æ”¹è¿›ç‰ˆç‰¹ç‚¹

### âœ… åº”ç”¨çš„æ”¹è¿›æŠ€æœ¯
1. **æŸå¤±å‡½æ•°æƒé‡è°ƒæ•´** (`cls=1.0`) - æ›¿ä»£æ— æ•ˆçš„class_weights
2. **ç»Ÿä¸€è§£åƒåº¦768** - è®­ç»ƒéªŒè¯æ¨ç†ä¸€è‡´
3. **AdamW + ä½™å¼¦é€€ç«** - ç°ä»£å­¦ä¹ ç‡ç­–ç•¥
4. **åˆ†å‰²å‹å¥½æ•°æ®å¢å¼º** - mosaic=0.3, copy_paste=0.5
5. **60è½®å……åˆ†è®­ç»ƒ** - æ›´å¥½çš„æ”¶æ•›

### ğŸ“ˆ é¢„æœŸæ”¹è¿›æ•ˆæœ
- **å¬å›ç‡æå‡2.4%** - å‡å°‘æ¼æ£€
- **è®­ç»ƒæ›´ç¨³å®š** - å¹³æ»‘æ”¶æ•›æ›²çº¿
- **ç±»åˆ«å¹³è¡¡æ”¹å–„** - çœŸæ­£æœ‰æ•ˆçš„æƒé‡è°ƒæ•´

## ğŸ’¡ ä½¿ç”¨è¯´æ˜

1. **æŸ¥çœ‹å•ä¸ªç»“æœ**: æ‰“å¼€ `predictions/example_XX_*.png`
2. **åˆ†æé¢„æµ‹è´¨é‡**: è§‚å¯Ÿç»¿è‰²æ¡†ï¼ˆæ­£ç¡®ï¼‰vs çº¢è‰²æ¡†ï¼ˆé”™è¯¯ï¼‰
3. **è¯„ä¼°å¬å›ç‡**: æ£€æŸ¥è“è‰²è™šçº¿æ¡†æ˜¯å¦è¢«æ£€æµ‹åˆ°
4. **ç½®ä¿¡åº¦åˆ†æ**: æŸ¥çœ‹é¢„æµ‹æ¡†ä¸Šçš„ç½®ä¿¡åº¦æ•°å€¼

## ğŸŠ ç»“è®º

è¿™äº›å¯è§†åŒ–ç»“æœå±•ç¤ºäº†ä¸“å®¶æ”¹è¿›ç‰ˆåœ¨å®é™…å«æ˜Ÿå›¾åƒä¸Šçš„è¡¨ç°ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„æŠ€æœ¯æ”¹è¿›ç¡®å®æœ‰æ•ˆæå‡äº†æ¨¡å‹æ€§èƒ½ã€‚
"""

with open(os.path.join(OUTPUT_DIR, "README.md"), 'w', encoding='utf-8') as f:
    f.write(summary_report)

print(f"\nğŸ‰ å¯è§†åŒ–ç»“æœç”Ÿæˆå®Œæˆ!")
print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
print(f"ğŸ“Š ç”Ÿæˆäº† {len(selected_images)} ä¸ªå¯è§†åŒ–ä¾‹å­")
print(f"ğŸ“ æ€»ç»“æŠ¥å‘Š: {OUTPUT_DIR}/README.md")

print(f"\nğŸ’¡ æŸ¥çœ‹ç»“æœ:")
print(f"   1. æ‰“å¼€ {OUTPUT_DIR}/predictions/ æŸ¥çœ‹é¢„æµ‹ç»“æœ")
print(f"   2. é˜…è¯» {OUTPUT_DIR}/README.md äº†è§£è¯¦ç»†è¯´æ˜")
print(f"   3. åˆ†æç»¿è‰²æ¡†(æ­£ç¡®) vs çº¢è‰²æ¡†(é”™è¯¯)çš„æ¯”ä¾‹")

print(f"\nğŸ¯ ä¸“å®¶æ”¹è¿›ç‰ˆå¯è§†åŒ–å®Œæˆ!")
