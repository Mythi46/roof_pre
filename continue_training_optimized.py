#!/usr/bin/env python3
"""
ç»§ç»­è®­ç»ƒè„šæœ¬ - ä¼˜åŒ–ç‰ˆæœ¬
Continue Training Script - Optimized Version

ä»ç°æœ‰çš„æœ€ä½³æƒé‡ç»§ç»­è®­ç»ƒï¼Œè§‚å¯Ÿæ˜¯å¦è¿˜æœ‰æå‡ç©ºé—´
ç­–ç•¥ï¼š10-15ä¸ªepochs + æ—©åœæœºåˆ¶ + æ€§èƒ½ç›‘æ§
"""

import os
import sys
import torch
import yaml
from pathlib import Path
from ultralytics import YOLO

def check_existing_training():
    """æ£€æŸ¥ç°æœ‰è®­ç»ƒç»“æœ"""
    print("ğŸ” æ£€æŸ¥ç°æœ‰è®­ç»ƒç»“æœ...")
    
    best_model_path = "runs/segment/improved_training_compatible/weights/best.pt"
    last_model_path = "runs/segment/improved_training_compatible/weights/last.pt"
    results_csv = "runs/segment/improved_training_compatible/results.csv"
    
    if not os.path.exists(best_model_path):
        print(f"âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹: {best_model_path}")
        return None, None
    
    if not os.path.exists(results_csv):
        print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœ: {results_csv}")
        return None, None
    
    # è¯»å–æœ€åçš„æ€§èƒ½æŒ‡æ ‡
    import pandas as pd
    df = pd.read_csv(results_csv)
    last_epoch = len(df) - 1  # å‡1å› ä¸ºæœ‰header
    last_metrics = df.iloc[-1]
    
    print(f"ğŸ“Š å½“å‰è®­ç»ƒçŠ¶æ€:")
    print(f"   å·²å®Œæˆepochs: {last_epoch}")
    print(f"   å½“å‰mAP@0.5: {last_metrics['metrics/mAP50(B)']:.4f}")
    print(f"   å½“å‰mAP@0.5:0.95: {last_metrics['metrics/mAP50-95(B)']:.4f}")
    print(f"   å½“å‰box_loss: {last_metrics['train/box_loss']:.4f}")
    print(f"   å½“å‰seg_loss: {last_metrics['train/seg_loss']:.4f}")
    
    return best_model_path, last_metrics

def continue_training_with_monitoring():
    """ç»§ç»­è®­ç»ƒå¹¶ç›‘æ§æ€§èƒ½æå‡"""
    
    print("ğŸš€ å¼€å§‹ç»§ç»­è®­ç»ƒ - è§‚å¯Ÿæ€§èƒ½æå‡æ½œåŠ›")
    print("="*60)
    
    # æ£€æŸ¥ç°æœ‰è®­ç»ƒ
    best_model_path, baseline_metrics = check_existing_training()
    if not best_model_path:
        return None
    
    # è®°å½•åŸºçº¿æ€§èƒ½
    baseline_map50 = baseline_metrics['metrics/mAP50(B)']
    baseline_map50_95 = baseline_metrics['metrics/mAP50-95(B)']
    
    print(f"\nğŸ¯ ç»§ç»­è®­ç»ƒç­–ç•¥:")
    print(f"   ç›®æ ‡epochs: 10-15ä¸ªé¢å¤–epochs")
    print(f"   æ—©åœè€å¿ƒå€¼: 10 epochs")
    print(f"   æœ€å°æ”¹å–„é˜ˆå€¼: 1% mAP@0.5")
    print(f"   åŸºçº¿mAP@0.5: {baseline_map50:.4f}")
    print(f"   ç›®æ ‡mAP@0.5: >{baseline_map50*1.01:.4f} (+1%)")
    
    # æ•°æ®é…ç½®
    DATA_YAML = "data/raw/new-2-1/data.yaml"
    
    if not os.path.exists(DATA_YAML):
        print(f"âŒ æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {DATA_YAML}")
        return None
    
    # åŠ è½½æœ€ä½³æ¨¡å‹ç»§ç»­è®­ç»ƒ
    print(f"\nğŸ”§ åŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}")
    model = YOLO(best_model_path)
    
    # æ£€æŸ¥GPU
    device = 0 if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    print(f"\nğŸš€ å¼€å§‹ç»§ç»­è®­ç»ƒ...")
    print("="*60)
    
    try:
        results = model.train(
            # åŸºæœ¬é…ç½®
            data=DATA_YAML,
            epochs=22,                    # ä»7ç»§ç»­åˆ°22 (é¢å¤–15ä¸ªepochs)
            imgsz=896,                    # ä¿æŒç›¸åŒçš„å›¾åƒå°ºå¯¸
            batch=16,
            device=device,
            
            # ä¼˜åŒ–å™¨é…ç½® (ä¿æŒä¸€è‡´)
            optimizer='AdamW',
            lr0=5e-5,                     # é™ä½å­¦ä¹ ç‡ (ä»1e-4é™åˆ°5e-5)
            lrf=0.01,
            momentum=0.937,
            weight_decay=0.0005,
            cos_lr=True,                  # ç»§ç»­ä½™å¼¦é€€ç«
            warmup_epochs=1,              # å‡å°‘warmup (å› ä¸ºæ˜¯ç»§ç»­è®­ç»ƒ)
            
            # æŸå¤±å‡½æ•°æƒé‡ (ä¿æŒä¼˜åŒ–åçš„é…ç½®)
            cls=1.2,
            box=5.0,
            dfl=2.5,
            
            # IoUé…ç½®
            iou=0.45,
            
            # æ•°æ®å¢å¼º (ç¨å¾®å‡å°‘ï¼Œå› ä¸ºæ¨¡å‹å·²ç»è¾ƒæˆç†Ÿ)
            mosaic=0.5,                   # ä»0.7é™åˆ°0.5
            copy_paste=0.1,               # ä»0.2é™åˆ°0.1
            close_mosaic=5,               # æœ€å5ä¸ªepochå…³é—­mosaic
            degrees=8,                    # ä»12é™åˆ°8
            translate=0.05,               # ä»0.1é™åˆ°0.05
            scale=0.3,                    # ä»0.5é™åˆ°0.3
            shear=1.0,                    # ä»2.0é™åˆ°1.0
            flipud=0.2,                   # ä»0.3é™åˆ°0.2
            fliplr=0.5,                   # ä¿æŒ
            hsv_h=0.01,                   # ä»0.02é™åˆ°0.01
            hsv_s=0.4,                    # ä»0.6é™åˆ°0.4
            hsv_v=0.3,                    # ä»0.4é™åˆ°0.3
            
            # æ—©åœå’Œç›‘æ§
            patience=10,                  # 10ä¸ªepochsæ— æ”¹å–„åˆ™åœæ­¢
            save_period=1,                # æ¯ä¸ªepochä¿å­˜
            amp=True,
            workers=0,
            cache=True,
            
            # è¾“å‡ºé…ç½®
            project='runs/segment',
            name='continue_training_optimized',
            plots=True,
            save=True,
            resume=False,                 # ä¸ä½¿ç”¨resumeï¼Œè€Œæ˜¯ä»best.ptå¼€å§‹æ–°çš„è®­ç»ƒ
        )
        
        print(f"\nğŸ‰ ç»§ç»­è®­ç»ƒå®Œæˆ!")
        print("="*60)
        
        # åˆ†æè®­ç»ƒç»“æœ
        if results:
            # æ£€æŸ¥æ–°çš„è®­ç»ƒç»“æœ
            new_results_dir = Path("runs/segment/continue_training_optimized")
            new_results_csv = new_results_dir / "results.csv"
            
            if new_results_csv.exists():
                import pandas as pd
                new_df = pd.read_csv(new_results_csv)
                final_metrics = new_df.iloc[-1]
                
                final_map50 = final_metrics['metrics/mAP50(B)']
                final_map50_95 = final_metrics['metrics/mAP50-95(B)']
                
                # è®¡ç®—æ”¹å–„
                map50_improvement = ((final_map50 - baseline_map50) / baseline_map50) * 100
                map50_95_improvement = ((final_map50_95 - baseline_map50_95) / baseline_map50_95) * 100
                
                print(f"ğŸ“Š ç»§ç»­è®­ç»ƒç»“æœåˆ†æ:")
                print(f"   åŸºçº¿mAP@0.5: {baseline_map50:.4f}")
                print(f"   æœ€ç»ˆmAP@0.5: {final_map50:.4f}")
                print(f"   mAP@0.5æ”¹å–„: {map50_improvement:+.2f}%")
                print(f"   ")
                print(f"   åŸºçº¿mAP@0.5:0.95: {baseline_map50_95:.4f}")
                print(f"   æœ€ç»ˆmAP@0.5:0.95: {final_map50_95:.4f}")
                print(f"   mAP@0.5:0.95æ”¹å–„: {map50_95_improvement:+.2f}%")
                
                # åˆ¤æ–­æ˜¯å¦å€¼å¾—ç»§ç»­
                if map50_improvement >= 1.0:
                    print(f"\nâœ… ç»§ç»­è®­ç»ƒæœ‰æ•ˆ! mAP@0.5æå‡äº†{map50_improvement:.2f}%")
                    print(f"   å»ºè®®: å¯ä»¥è€ƒè™‘è¿›ä¸€æ­¥è®­ç»ƒ")
                elif map50_improvement >= 0.5:
                    print(f"\nâš–ï¸ ç»§ç»­è®­ç»ƒæœ‰å°å¹…æå‡: {map50_improvement:.2f}%")
                    print(f"   å»ºè®®: è¾¹é™…æ”¶ç›Šè¾ƒå°ï¼Œå¯ä»¥åœæ­¢")
                else:
                    print(f"\nâš ï¸ ç»§ç»­è®­ç»ƒæ”¶ç›Šå¾ˆå°: {map50_improvement:.2f}%")
                    print(f"   å»ºè®®: åœæ­¢è®­ç»ƒï¼Œä½¿ç”¨ä¹‹å‰çš„æœ€ä½³æ¨¡å‹")
                
                # æ£€æŸ¥æœ€ä½³æ¨¡å‹
                best_model = new_results_dir / "weights" / "best.pt"
                if best_model.exists():
                    size_mb = best_model.stat().st_size / (1024 * 1024)
                    print(f"\nğŸ’¾ æ–°çš„æœ€ä½³æ¨¡å‹: {best_model} ({size_mb:.1f}MB)")
                
                # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
                comparison_report = {
                    'baseline_metrics': {
                        'mAP50': float(baseline_map50),
                        'mAP50_95': float(baseline_map50_95)
                    },
                    'final_metrics': {
                        'mAP50': float(final_map50),
                        'mAP50_95': float(final_map50_95)
                    },
                    'improvements': {
                        'mAP50_percent': float(map50_improvement),
                        'mAP50_95_percent': float(map50_95_improvement)
                    },
                    'recommendation': 'continue' if map50_improvement >= 1.0 else 'stop'
                }
                
                import json
                with open('results/continue_training_analysis.json', 'w') as f:
                    json.dump(comparison_report, f, indent=2)
                
                print(f"ğŸ“‹ è¯¦ç»†å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: results/continue_training_analysis.json")
        
        return results
        
    except Exception as e:
        print(f"âŒ ç»§ç»­è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ ç»§ç»­è®­ç»ƒ - æ€§èƒ½æå‡éªŒè¯")
    print("="*50)
    
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    Path("results").mkdir(exist_ok=True)
    
    try:
        results = continue_training_with_monitoring()
        if results:
            print(f"\nâœ… ç»§ç»­è®­ç»ƒæµç¨‹å®Œæˆ!")
            print(f"ğŸ“ æ–°è®­ç»ƒç»“æœ: runs/segment/continue_training_optimized/")
        else:
            print(f"\nâŒ ç»§ç»­è®­ç»ƒæµç¨‹å¤±è´¥!")
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
