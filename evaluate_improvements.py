#!/usr/bin/env python3
"""
æ”¹è¿›æ•ˆæœè¯„ä¼°è„šæœ¬
Improvement Evaluation Script

å¯¹æ¯”æ”¹è¿›å‰åçš„æ¨¡å‹æ€§èƒ½ï¼Œç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š
"""

import os
import sys
import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import pandas as pd

def find_latest_training_results():
    """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç»“æœ"""
    runs_dir = Path("runs/segment")
    
    if not runs_dir.exists():
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœç›®å½•")
        return None, None
    
    # æŸ¥æ‰¾æ”¹è¿›ç‰ˆç»“æœ
    improved_dirs = list(runs_dir.glob("improved_training_v*"))
    improved_dir = max(improved_dirs, key=lambda x: x.stat().st_mtime) if improved_dirs else None
    
    # æŸ¥æ‰¾åŸå§‹ç‰ˆç»“æœ
    original_dirs = [d for d in runs_dir.iterdir() if d.is_dir() and "improved" not in d.name]
    original_dir = max(original_dirs, key=lambda x: x.stat().st_mtime) if original_dirs else None
    
    return improved_dir, original_dir

def load_training_results(result_dir):
    """åŠ è½½è®­ç»ƒç»“æœ"""
    if not result_dir or not result_dir.exists():
        return None
    
    results_file = result_dir / "results.csv"
    if not results_file.exists():
        print(f"âš ï¸ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {results_file}")
        return None
    
    try:
        df = pd.read_csv(results_file)
        # æ¸…ç†åˆ—åä¸­çš„ç©ºæ ¼
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        print(f"âŒ åŠ è½½ç»“æœå¤±è´¥: {e}")
        return None

def evaluate_model_performance(model_path, data_yaml):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None
    
    print(f"ğŸ“Š è¯„ä¼°æ¨¡å‹: {model_path}")
    
    try:
        model = YOLO(model_path)
        
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        results = model.val(
            data=data_yaml,
            imgsz=896,
            conf=0.35,
            iou=0.6,
            save_json=True,
            save_hybrid=True
        )
        
        # æå–å…³é”®æŒ‡æ ‡
        metrics = {
            'mAP50': results.box.map50 if hasattr(results, 'box') else results.seg.map50,
            'mAP50_95': results.box.map if hasattr(results, 'box') else results.seg.map,
            'precision': results.box.mp if hasattr(results, 'box') else results.seg.mp,
            'recall': results.box.mr if hasattr(results, 'box') else results.seg.mr,
        }
        
        # æŒ‰ç±»åˆ«çš„æŒ‡æ ‡
        if hasattr(results, 'seg'):
            metrics['class_map50'] = results.seg.map50_per_class.tolist()
            metrics['class_map50_95'] = results.seg.map_per_class.tolist()
        elif hasattr(results, 'box'):
            metrics['class_map50'] = results.box.map50_per_class.tolist()
            metrics['class_map50_95'] = results.box.map_per_class.tolist()
        
        return metrics
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        return None

def compare_training_curves(improved_df, original_df):
    """å¯¹æ¯”è®­ç»ƒæ›²çº¿"""
    print("ğŸ“ˆ ç”Ÿæˆè®­ç»ƒæ›²çº¿å¯¹æ¯”å›¾...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('è®­ç»ƒæ”¹è¿›æ•ˆæœå¯¹æ¯” (Training Improvement Comparison)', fontsize=16)
    
    # å…³é”®æŒ‡æ ‡åˆ—åæ˜ å°„
    metric_columns = {
        'mAP50': ['metrics/mAP50(B)', 'val/mAP50', 'mAP50'],
        'mAP50_95': ['metrics/mAP50-95(B)', 'val/mAP50-95', 'mAP50-95'],
        'box_loss': ['train/box_loss', 'box_loss'],
        'cls_loss': ['train/cls_loss', 'cls_loss']
    }
    
    def find_column(df, possible_names):
        for name in possible_names:
            if name in df.columns:
                return name
        return None
    
    # ç»˜åˆ¶mAP50å¯¹æ¯”
    ax = axes[0, 0]
    if improved_df is not None:
        col = find_column(improved_df, metric_columns['mAP50'])
        if col:
            ax.plot(improved_df[col], label='æ”¹è¿›ç‰ˆ', linewidth=2, color='red')
    
    if original_df is not None:
        col = find_column(original_df, metric_columns['mAP50'])
        if col:
            ax.plot(original_df[col], label='åŸå§‹ç‰ˆ', linewidth=2, color='blue')
    
    ax.set_title('mAP@0.5 å¯¹æ¯”')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('mAP@0.5')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶mAP50-95å¯¹æ¯”
    ax = axes[0, 1]
    if improved_df is not None:
        col = find_column(improved_df, metric_columns['mAP50_95'])
        if col:
            ax.plot(improved_df[col], label='æ”¹è¿›ç‰ˆ', linewidth=2, color='red')
    
    if original_df is not None:
        col = find_column(original_df, metric_columns['mAP50_95'])
        if col:
            ax.plot(original_df[col], label='åŸå§‹ç‰ˆ', linewidth=2, color='blue')
    
    ax.set_title('mAP@0.5:0.95 å¯¹æ¯”')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('mAP@0.5:0.95')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶box_losså¯¹æ¯”
    ax = axes[1, 0]
    if improved_df is not None:
        col = find_column(improved_df, metric_columns['box_loss'])
        if col:
            ax.plot(improved_df[col], label='æ”¹è¿›ç‰ˆ', linewidth=2, color='red')
    
    if original_df is not None:
        col = find_column(original_df, metric_columns['box_loss'])
        if col:
            ax.plot(original_df[col], label='åŸå§‹ç‰ˆ', linewidth=2, color='blue')
    
    ax.set_title('Box Loss å¯¹æ¯”')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Box Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶cls_losså¯¹æ¯”
    ax = axes[1, 1]
    if improved_df is not None:
        col = find_column(improved_df, metric_columns['cls_loss'])
        if col:
            ax.plot(improved_df[col], label='æ”¹è¿›ç‰ˆ', linewidth=2, color='red')
    
    if original_df is not None:
        col = find_column(original_df, metric_columns['cls_loss'])
        if col:
            ax.plot(original_df[col], label='åŸå§‹ç‰ˆ', linewidth=2, color='blue')
    
    ax.set_title('Classification Loss å¯¹æ¯”')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Cls Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/training_comparison.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š è®­ç»ƒæ›²çº¿å¯¹æ¯”å›¾å·²ä¿å­˜: results/training_comparison.png")

def generate_improvement_report(improved_metrics, original_metrics, class_names):
    """ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š"""
    print("ğŸ“‹ ç”Ÿæˆæ”¹è¿›æ•ˆæœæŠ¥å‘Š...")
    
    report = []
    report.append("# ğŸ  å±‹é¡¶æ£€æµ‹æ¨¡å‹æ”¹è¿›æ•ˆæœæŠ¥å‘Š")
    report.append("=" * 50)
    report.append("")
    
    if improved_metrics and original_metrics:
        # æ•´ä½“æ€§èƒ½å¯¹æ¯”
        report.append("## ğŸ“Š æ•´ä½“æ€§èƒ½å¯¹æ¯”")
        report.append("")
        report.append("| æŒ‡æ ‡ | åŸå§‹ç‰ˆ | æ”¹è¿›ç‰ˆ | æå‡å¹…åº¦ |")
        report.append("|------|--------|--------|----------|")
        
        for metric in ['mAP50', 'mAP50_95', 'precision', 'recall']:
            if metric in improved_metrics and metric in original_metrics:
                original_val = original_metrics[metric]
                improved_val = improved_metrics[metric]
                improvement = ((improved_val - original_val) / original_val) * 100
                
                report.append(f"| {metric} | {original_val:.3f} | {improved_val:.3f} | {improvement:+.1f}% |")
        
        report.append("")
        
        # æŒ‰ç±»åˆ«æ€§èƒ½å¯¹æ¯”
        if 'class_map50' in improved_metrics and 'class_map50' in original_metrics:
            report.append("## ğŸ¯ æŒ‰ç±»åˆ«æ€§èƒ½å¯¹æ¯” (mAP@0.5)")
            report.append("")
            report.append("| ç±»åˆ« | åŸå§‹ç‰ˆ | æ”¹è¿›ç‰ˆ | æå‡å¹…åº¦ |")
            report.append("|------|--------|--------|----------|")
            
            for i, class_name in enumerate(class_names):
                if i < len(original_metrics['class_map50']) and i < len(improved_metrics['class_map50']):
                    original_val = original_metrics['class_map50'][i]
                    improved_val = improved_metrics['class_map50'][i]
                    improvement = ((improved_val - original_val) / original_val) * 100 if original_val > 0 else 0
                    
                    report.append(f"| {class_name} | {original_val:.3f} | {improved_val:.3f} | {improvement:+.1f}% |")
            
            report.append("")
    
    elif improved_metrics:
        report.append("## ğŸ“Š æ”¹è¿›ç‰ˆæ€§èƒ½æŒ‡æ ‡")
        report.append("")
        for metric, value in improved_metrics.items():
            if isinstance(value, (int, float)):
                report.append(f"- **{metric}**: {value:.3f}")
        report.append("")
    
    # æ”¹è¿›æªæ–½æ€»ç»“
    report.append("## ğŸ”§ å®æ–½çš„æ”¹è¿›æªæ–½")
    report.append("")
    report.append("1. **ç±»åˆ«æƒé‡ä¼˜åŒ–**: ä½¿ç”¨æ­£ç¡®çš„CLIä¼ å‚æ–¹å¼")
    report.append("2. **æ¨¡å‹å‡çº§**: yolov8m-seg â†’ yolov8l-seg (æ›´å¥½ç‰¹å¾åˆ†è¾¨ç‡)")
    report.append("3. **æŸå¤±æƒé‡è°ƒæ•´**: box=5.0, cls=1.2, dfl=2.5")
    report.append("4. **IoUä¼˜åŒ–**: ä½¿ç”¨GIoUæ›¿ä»£CIoU (æ›´é€‚åˆé•¿æ¡å½¢ç›®æ ‡)")
    report.append("5. **æ•°æ®å¢å¼º**: å¯ç”¨copy_paste=0.2 (å°‘æ•°ç±»å¢å¼º)")
    report.append("6. **é‡‡æ ·ç­–ç•¥**: å¯ç”¨weightedé‡‡æ ·")
    report.append("7. **å­¦ä¹ ç‡ç­–ç•¥**: ä½™å¼¦é€€ç« + é™ä½åˆå§‹å­¦ä¹ ç‡")
    report.append("")
    
    # ä¿å­˜æŠ¥å‘Š
    with open('results/improvement_report.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print("ğŸ“‹ æ”¹è¿›æŠ¥å‘Šå·²ä¿å­˜: results/improvement_report.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å±‹é¡¶æ£€æµ‹æ¨¡å‹æ”¹è¿›æ•ˆæœè¯„ä¼°")
    print("=" * 50)
    
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    Path("results").mkdir(exist_ok=True)
    
    # æŸ¥æ‰¾è®­ç»ƒç»“æœ
    improved_dir, original_dir = find_latest_training_results()
    
    print(f"ğŸ“ è®­ç»ƒç»“æœç›®å½•:")
    print(f"   æ”¹è¿›ç‰ˆ: {improved_dir}")
    print(f"   åŸå§‹ç‰ˆ: {original_dir}")
    
    # åŠ è½½è®­ç»ƒæ›²çº¿æ•°æ®
    improved_df = load_training_results(improved_dir) if improved_dir else None
    original_df = load_training_results(original_dir) if original_dir else None
    
    # ç”Ÿæˆè®­ç»ƒæ›²çº¿å¯¹æ¯”
    if improved_df is not None or original_df is not None:
        compare_training_curves(improved_df, original_df)
    
    # è¯„ä¼°æ¨¡å‹æ€§èƒ½
    data_yaml = "data/raw/new-2-1/data.yaml"
    improved_metrics = None
    original_metrics = None
    
    if improved_dir:
        best_model = improved_dir / "weights" / "best.pt"
        if best_model.exists():
            improved_metrics = evaluate_model_performance(str(best_model), data_yaml)
    
    if original_dir:
        best_model = original_dir / "weights" / "best.pt"
        if best_model.exists():
            original_metrics = evaluate_model_performance(str(best_model), data_yaml)
    
    # è·å–ç±»åˆ«åç§°
    class_names = ['Baren-Land', 'farm', 'rice-fields', 'roof']
    
    # ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š
    generate_improvement_report(improved_metrics, original_metrics, class_names)
    
    # æ‰“å°æ€»ç»“
    print(f"\nğŸ“Š è¯„ä¼°å®Œæˆ!")
    print(f"   è®­ç»ƒæ›²çº¿å¯¹æ¯”: results/training_comparison.png")
    print(f"   æ”¹è¿›æ•ˆæœæŠ¥å‘Š: results/improvement_report.md")
    
    if improved_metrics and original_metrics:
        mAP50_improvement = ((improved_metrics['mAP50'] - original_metrics['mAP50']) / original_metrics['mAP50']) * 100
        print(f"   mAP@0.5 æ”¹è¿›: {mAP50_improvement:+.1f}%")

if __name__ == "__main__":
    main()
